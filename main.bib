@article{mnih_atari,
  added-at = {2019-07-12T20:11:01.000+0200},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  note = {cite arxiv:1312.5602Comment: NIPS Deep Learning Workshop 2013},
  title = {Playing Atari with Deep Reinforcement Learning},
  year = 2013
}
%
@article{silver_go,
  added-at = {2017-12-15T02:14:58.000+0100},
  author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/2ecdfbfcceb55ee5f14c1c375ad71f2cb/achakraborty},
  description = {Mastering the game of Go without human knowledge | Nature},
  journal = {Nature},
  keywords = {2017 deep-learning deepmind google paper reinforcement-learning},
  month = oct,
  pages = {354--},
  publisher = {Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
  timestamp = {2017-12-15T02:14:58.000+0100},
  title = {Mastering the game of Go without human knowledge},
  volume = 550,
  year = 2017
}
%
@misc{jumper_alphafold,
    author = {Jumper, John and Evans, Richard and Pritzel, Alexander Green, Tim and Figurnov, Michael and Tunyasuvunakool, Kathryn and Ronneberger, Olaf and Bates, Russ and Žídek, Augustin and Bridgland, Alex and Meyer, Clemens and A A Kohl, Simon and Potapenko, Anna and J Ballard, Andrew and Cowie, Andrew and Romera-Paredes, Bernardino and  Nikolov, Stanislav and Jain, Rishub  and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Steinegger, Martin and Pacholska, Michalina and Silver, David and Vinyals, Oriol and W Senior, Andrew and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis},
    title = {High Accuracy Protein Structure Prediction Using Deep Learning},
    year = 2020
}
%
@article{goodfellow_explaining,
  added-at = {2019-09-26T15:53:30.000+0200},
  author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
  description = {[1412.6572] Explaining and Harnessing Adversarial Examples},
  keywords = {adversarial robustness},
  title = {Explaining and Harnessing Adversarial Examples},
  url = {http://arxiv.org/abs/1412.6572},
  year = 2014
}
%
@inproceedings{aml_book,
author = {Huang, Ling and Joseph, Anthony D. and Nelson, Blaine and Rubinstein, Benjamin I.P. and Tygar, J. D.},
title = {Adversarial Machine Learning},
year = {2011},
isbn = {9781450310031},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/2046684.2046692},
booktitle = {Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence},
pages = {43–58},
numpages = {16},
keywords = {computer security, statistical learning, machine learning, intrusion detection, spam filters, security metrics, adversarial learning, game theory},
location = {Chicago, Illinois, USA},
series = {AISec '11}
}
%
@techreport{Ghaoui_robust_classification,
    Author = {El Ghaoui, Laurent and Lanckriet, Gert R. G. and Natsoulis, Georges},
    Title = {Robust Classification with Interval Data},
    Institution = {EECS Department, University of California, Berkeley},
    Year = {2003},
    Month = {Oct},
    Number = {UCB/CSD-03-1279},
}
%
@article{Lanckriet_robust_minimax,
author = {Lanckriet, Gert R.G. and Ghaoui, Laurent El and Bhattacharyya, Chiranjib and Jordan, Michael I.},
title = {A Robust Minimax Approach to Classification},
year = {2003},
issue_date = {3/1/2003},
publisher = {JMLR.org},
volume = {3},
issn = {1532-4435},
doi = {10.1162/153244303321897726},
journal = {J. Mach. Learn. Res.},
pages = {555–582},
numpages = {28},
}
%
@inproceedings{Globerson_robust_deletion,
author = {Globerson, Amir and Roweis, Sam},
title = {Nightmare at Test Time: Robust Learning by Feature Deletion},
year = {2006},
isbn = {1595933832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/1143844.1143889},
booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
pages = {353–360},
numpages = {8},
location = {Pittsburgh, Pennsylvania, USA},
series = {ICML '06}
}
%
@Article{dekel_corrupted_learning,
author = {Dekel, Ofer and Shamir, Ohad and Xiao, Lin},
title = {Learning to Classify with Missing and Corrupted Features},
year = {2009},
month = {June},
publisher = {Springer Verlag},
journal = {Machine Learning Journal},
edition = {Machine Learning Journal},
}
%
@article{bruckner_static_aml,
  author  = {Michael Br{{\"u}}ckner and Christian Kanzow and Tobias Scheffer},
  title   = {Static Prediction Games for Adversarial Learning Problems},
  journal = {Journal of Machine Learning Research},
  year    = {2012},
  volume  = {13},
  number  = {85},
  pages   = {2617-2654},
  url     = {http://jmlr.org/papers/v13/brueckner12a.html}
}
%
@ARTICLE{dritsoula_game_ml, 
author={L. {Dritsoula} and P. {Loiseau} and J. {Musacchio}},  journal={IEEE Transactions on Information Forensics and Security},   title={A Game-Theoretic Analysis of Adversarial Classification},   year={2017},  volume={12},  number={12},  pages={3094-3109},  doi={10.1109/TIFS.2017.2718494}}
%
@article{barreno_security_ml,
author = {Barreno, Marco and Nelson, Blaine and Joseph, Anthony D. and Tygar, J. D.},
title = {The Security of Machine Learning},
year = {2010},
issue_date = {November  2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {81},
number = {2},
issn = {0885-6125},
doi = {10.1007/s10994-010-5188-5},
journal = {Mach. Learn.},
month = nov,
pages = {121–148},
numpages = {28},
}
%
@article{murat_adversarial_classification,
  author    = {Murat Kantarcioglu and
               Bowei Xi and
               Chris Clifton},
  title     = {Classifier evaluation and attribute selection against active adversaries},
  journal   = {Data Min. Knowl. Discov.},
  volume    = {22},
  number    = {1-2},
  pages     = {291--335},
  year      = {2011},
  doi       = {10.1007/s10618-010-0197-3},
  timestamp = {Sat, 20 May 2017 00:25:07 +0200},
}
%
@INPROCEEDINGS{liu_game_theoretical_aml,
author={W. {Liu} and S. {Chawla}},  booktitle={2009 IEEE International Conference on Data Mining Workshops},   title={A Game Theoretical Model for Adversarial Learning},   year={2009},  volume={},  number={},  pages={25-30},  doi={10.1109/ICDMW.2009.9}}
%
@inproceedings{bruckner_stackelberg,
author = {Br\"{u}ckner, Michael and Scheffer, Tobias},
title = {Stackelberg Games for Adversarial Prediction Problems},
year = {2011},
isbn = {9781450308137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/2020408.2020495},
booktitle = {Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {547–555},
numpages = {9},
keywords = {adversarial classification, spam filtering, stackelberg competition, prediction game},
location = {San Diego, California, USA},
series = {KDD '11}
}
%
@article{jeroslow_polynomial_bilevel,
  author    = {Robert G. Jeroslow},
  title     = {The polynomial hierarchy and a simple model for competitive analysis},
  journal   = {Math. Program.},
  volume    = {32},
  number    = {2},
  pages     = {146--164},
  year      = {1985},
  doi       = {10.1007/BF01586088},
  timestamp = {Sat, 27 May 2017 14:25:33 +0200},
}
%
@inbook{naveiro_gradient_stackelberg,
author = {Naveiro, Roi and Rios, David},
year = {2019},
month = {10},
pages = {126-140},
title = {Gradient Methods for Solving Stackelberg Games},
isbn = {978-3-030-31488-0},
doi = {10.1007/978-3-030-31489-7_9}
}
%
@MISC{colson_bilevel,
    author = {Benoît Colson and Patrice Marcotte and Gilles Savard},
    title = { An overview of bilevel optimization},
    year = {2007}
}
%
@article{harsanyi_bayesian_games,
author = {Harsanyi, John C.},
title = {Games with Incomplete Information Played by “Bayesian” Players, I–III: Part I. The Basic Model},
journal = {Management Science},
volume = {50},
number = {12\_supplement},
pages = {1804-1817},
year = {2004},
doi = {10.1287/mnsc.1040.0270},
}
%
@inproceedings{groshan_bayesian_reg,
author = {Gro\ss{}hans, Michael and Sawade, Christoph and Br\"{u}ckner, Michael and Scheffer, Tobias},
title = {Bayesian Games for Adversarial Regression Problems},
year = {2013},
publisher = {JMLR.org},
booktitle = {Proceedings of the 30th International Conference on International Conference on Machine Learning - Volume 28},
pages = {III–55–III–63},
numpages = {9},
location = {Atlanta, GA, USA},
series = {ICML'13}
}
%
@inproceedings{conitzer_bayesian_game,
author = {Conitzer, Vincent and Sandholm, Tuomas},
title = {Computing the Optimal Strategy to Commit To},
year = {2006},
isbn = {1595932364},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/1134707.1134717},
pages = {82–90},
numpages = {9},
keywords = {nash equilibrium, game theory, commitment, bayesian games, stackelberg, normalform games, leadership},
location = {Ann Arbor, Michigan, USA},
series = {EC '06}
}
%
@article{ahuja2020invariant,
  title={Invariant risk minimization games},
  author={Ahuja, Kartik and Shanmugam, Karthikeyan and Varshney, Kush and Dhurandhar, Amit},
  journal={arXiv preprint arXiv:2002.04692},
  year={2020}
}
%
@article{ahuja2020linear,
  title={Linear Regression Games: Convergence Guarantees to Approximate Out-of-Distribution Solutions},
  author={Ahuja, Kartik and Shanmugam, Karthikeyan and Dhurandhar, Amit},
  journal={arXiv preprint arXiv:2010.15234},
  year={2020}
}
%
@article{Watts1998Collective,
  abstract = {{Networks of coupled dynamical systems have been used to model biological oscillators1, 2, 3, 4, Josephson junction arrays5,6, excitable media7, neural networks8, 9, 10, spatial games11, genetic control networks12 and many other self-organizing systems. Ordinarily, the connection topology is assumed to be either completely regular or completely random. But many biological, technological and social networks lie somewhere between these two extremes. Here we explore simple models of networks that can be tuned through this middle ground: regular networks 'rewired' to introduce increasing amounts of disorder. We find that these systems can be highly clustered, like regular lattices, yet have small characteristic path lengths, like random graphs. We call them 'small-world' networks, by analogy with the small-world phenomenon13,14 (popularly known as six degrees of separation15). The neural network of the worm Caenorhabditis elegans, the power grid of the western United States, and the collaboration graph of film actors are shown to be small-world networks. Models of dynamical systems with small-world coupling display enhanced signal-propagation speed, computational power, and synchronizability. In particular, infectious diseases spread more easily in small-world networks than in regular lattices.}},
  added-at = {2019-06-10T14:53:09.000+0200},
  address = {Department of Theoretical and Applied Mechanics, Cornell University, Ithaca, New York 14853, USA. djw24@columbia.edu},
  author = {Watts, Duncan J. and Strogatz, Steven H.},
  citeulike-article-id = {99},
  day = 04,
  doi = {10.1038/30918},
  issn = {0028-0836},
  journal = {Nature},
  keywords = {small-world networks},
  month = jun,
  number = 6684,
  pages = {440--442},
  pmid = {9623998},
  priority = {2},
  publisher = {Nature Publishing Group},
  title = {{Collective dynamics of 'small-world' networks}},
  volume = 393,
  year = 1998
}

